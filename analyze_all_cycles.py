#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰¹é‡åˆ†ææ‰€æœ‰å‘¨æœŸçš„è®¢å•å’ŒPnLï¼Œä¸ºæ¯ä¸ªå‘¨æœŸç”Ÿæˆç‹¬ç«‹çš„CSVå’Œåˆ†ææŠ¥å‘Š
"""

import re
import os
import csv
from datetime import datetime
from collections import defaultdict
from pathlib import Path

def parse_log_line(line):
    """è§£ææ—¥å¿—è¡Œï¼Œæå–æ—¶é—´å’Œæ¶ˆæ¯"""
    time_match = re.search(r'\[(\d{2}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})\]', line)
    if time_match:
        try:
            time_str = time_match.group(1)
            dt = datetime.strptime(time_str, '%y-%m-%d %H:%M:%S')
            timestamp = int(dt.timestamp())
            return {
                'timestamp': timestamp,
                'time': time_str
            }
        except:
            pass
    return None

def extract_order_from_line(line, parsed):
    """ä»è®¢å•æ—¥å¿—ä¸­æå–è®¢å•ä¿¡æ¯"""
    if not parsed:
        return None
    
    # å°è¯•å¤šç§æ ¼å¼åŒ¹é…è®¢å•è®°å½•
    patterns = [
        (r'ğŸ“.*çº¸äº¤æ˜“.*æ¨¡æ‹Ÿä¸‹å•.*orderID=([^\s,]+).*tokenType=(\w+).*side=(\w+).*price=([\d.]+).*size=([\d.]+)', 'full'),
        (r'æ¨¡æ‹Ÿä¸‹å•.*orderID=([^\s,]+).*tokenType=(\w+).*price=([\d.]+).*size=([\d.]+)', 'simple'),
        (r'çº¸äº¤æ˜“.*æ¨¡æ‹Ÿä¸‹å•.*orderID=([^\s,]+).*tokenType=(\w+).*price=([\d.]+).*size=([\d.]+)', 'simple2'),
    ]
    
    for pattern, ptype in patterns:
        match = re.search(pattern, line)
        if match:
            if ptype == 'full':
                order_id, token, side, price, size = match.groups()
            else:
                order_id, token, price, size = match.groups()
                side = 'BUY'
            
            token = token.lower()
            direction = 'Up' if token == 'up' else 'Down' if token == 'down' else ''
            outcome_index = 0 if token == 'up' else 1 if token == 'down' else 0
            
            market_match = re.search(r'market=([^\s,]+)', line)
            market = market_match.group(1) if market_match else ''
            
            return {
                'timestamp': parsed['timestamp'],
                'time': parsed['time'],
                'order_id': order_id,
                'action': side.upper(),
                'direction': direction,
                'market': market,
                'price': float(price),
                'size': float(size),
                'usdc_amount': float(price) * float(size),
                'outcome_index': outcome_index,
                'type': 'order'
            }
    
    return None

def extract_position_stats(line, parsed):
    """ä»æ—¥å¿—è¡Œä¸­æå–æŒä»“ç»Ÿè®¡"""
    if 'æŒä»“ç»Ÿè®¡' not in line or not parsed:
        return None
    
    up_cost_match = re.search(r'upCost=([\d.]+)', line)
    down_cost_match = re.search(r'downCost=([\d.]+)', line)
    up_shares_match = re.search(r'upShares=([\d.]+)', line)
    down_shares_match = re.search(r'downShares=([\d.]+)', line)
    worst_pnl_match = re.search(r'worstPnL=([\d.]+)', line)
    unhedged_match = re.search(r'unhedged=([\d.]+)', line)
    remaining_match = re.search(r'remainingSeconds=(\d+)', line)
    market_match = re.search(r'market=([^\s,]+)', line)
    
    if not (up_shares_match and down_shares_match):
        return None
    
    return {
        'timestamp': parsed['timestamp'],
        'time': parsed['time'],
        'market': market_match.group(1) if market_match else '',
        'up_shares': float(up_shares_match.group(1)),
        'down_shares': float(down_shares_match.group(1)),
        'up_cost': float(up_cost_match.group(1)) if up_cost_match else 0,
        'down_cost': float(down_cost_match.group(1)) if down_cost_match else 0,
        'worst_pnl': float(worst_pnl_match.group(1)) if worst_pnl_match else 0,
        'unhedged': float(unhedged_match.group(1)) if unhedged_match else 0,
        'remaining': int(remaining_match.group(1)) if remaining_match else 0
    }

def extract_cycle_id_from_market(market_slug):
    """ä»market slugä¸­æå–å‘¨æœŸID"""
    match = re.search(r'(\d{10})$', market_slug)
    if match:
        return match.group(1)
    return None

def generate_csv_for_cycle(cycle_id, cycle_data, output_dir="lab"):
    """ä¸ºå•ä¸ªå‘¨æœŸç”ŸæˆCSVæ–‡ä»¶"""
    orders = cycle_data['orders']
    if not orders:
        return None
    
    # æŒ‰æ—¶é—´æ’åº
    orders.sort(key=lambda x: x['timestamp'])
    
    # ç”ŸæˆCSVæ–‡ä»¶å
    csv_filename = f"bot_cyclehedge_cycle_{cycle_id}.csv"
    csv_path = os.path.join(output_dir, csv_filename)
    
    # å†™å…¥CSVï¼ˆä½¿ç”¨4ä½å¹´ä»½æ ¼å¼ï¼‰
    with open(csv_path, 'w', encoding='utf-8', newline='') as f:
        fieldnames = ['æ—¶é—´æˆ³', 'æ—¶é—´', 'åŠ¨ä½œ', 'æ–¹å‘', 'å¸‚åœº', 'ä»·æ ¼', 'æ•°é‡', 'USDCé‡‘é¢', 'OutcomeIndex']
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        
        for order in orders:
            # è½¬æ¢æ—¶é—´ä¸º4ä½å¹´ä»½æ ¼å¼
            dt = datetime.fromtimestamp(order['timestamp'])
            time_str = dt.strftime('%Y-%m-%d %H:%M:%S')
            
            writer.writerow({
                'æ—¶é—´æˆ³': order['timestamp'],
                'æ—¶é—´': time_str,
                'åŠ¨ä½œ': order['action'],
                'æ–¹å‘': order['direction'],
                'å¸‚åœº': order['market'],
                'ä»·æ ¼': f"{order['price']:.6f}",
                'æ•°é‡': f"{order['size']:.1f}",
                'USDCé‡‘é¢': f"{order['usdc_amount']:.6f}",
                'OutcomeIndex': order['outcome_index']
            })
    
    return csv_path

def analyze_cycle_pnl(cycle_id, cycle_data):
    """åˆ†æå•ä¸ªå‘¨æœŸçš„PnL"""
    orders = cycle_data['orders']
    position_stats = cycle_data['position_stats']
    
    if not position_stats:
        return None
    
    # è·å–æœ€ç»ˆæŒä»“ç»Ÿè®¡
    last_stat = position_stats[-1]
    first_stat = position_stats[0]
    
    final_up_shares = last_stat['up_shares']
    final_down_shares = last_stat['down_shares']
    final_up_cost = last_stat['up_cost']
    final_down_cost = last_stat['down_cost']
    total_cost = final_up_cost + final_down_cost
    worst_pnl = last_stat['worst_pnl']
    
    # è®¡ç®—PnL
    pnl_up_win = final_up_shares * 1.0 - total_cost if final_up_shares > 0 else 0
    pnl_down_win = final_down_shares * 1.0 - total_cost if final_down_shares > 0 else 0
    worst_case_pnl = min(pnl_up_win, pnl_down_win) if final_up_shares > 0 and final_down_shares > 0 else 0
    
    # æŒä»“å¹³è¡¡åº¦
    min_shares = min(final_up_shares, final_down_shares)
    max_shares = max(final_up_shares, final_down_shares)
    balance_ratio = (min_shares / max_shares * 100) if max_shares > 0 else 0
    
    # å¹³å‡æˆæœ¬
    up_avg_price = final_up_cost / final_up_shares if final_up_shares > 0 else 0
    down_avg_price = final_down_cost / final_down_shares if final_down_shares > 0 else 0
    
    # è®¢å•ç»Ÿè®¡
    up_orders = [o for o in orders if o['direction'] == 'Up']
    down_orders = [o for o in orders if o['direction'] == 'Down']
    
    up_order_total = sum(o['size'] for o in up_orders)
    down_order_total = sum(o['size'] for o in down_orders)
    up_order_amount = sum(o['usdc_amount'] for o in up_orders)
    down_order_amount = sum(o['usdc_amount'] for o in down_orders)
    
    return {
        'cycle_id': cycle_id,
        'market_slug': cycle_data['market_slug'],
        'log_file': cycle_data.get('log_file', ''),
        'log_create_time': cycle_data.get('log_create_time', ''),
        'orders_count': len(orders),
        'up_orders_count': len(up_orders),
        'down_orders_count': len(down_orders),
        'up_order_total': up_order_total,
        'down_order_total': down_order_total,
        'up_order_amount': up_order_amount,
        'down_order_amount': down_order_amount,
        'first_order_time': orders[0]['time'] if orders else None,
        'last_order_time': orders[-1]['time'] if orders else None,
        'first_stat_time': first_stat['time'],
        'last_stat_time': last_stat['time'],
        'final_up_shares': final_up_shares,
        'final_down_shares': final_down_shares,
        'final_up_cost': final_up_cost,
        'final_down_cost': final_down_cost,
        'total_cost': total_cost,
        'pnl_up_win': pnl_up_win,
        'pnl_down_win': pnl_down_win,
        'worst_case_pnl': worst_case_pnl,
        'worst_pnl_from_stat': worst_pnl,
        'balance_ratio': balance_ratio,
        'up_avg_price': up_avg_price,
        'down_avg_price': down_avg_price,
        'stats_count': len(position_stats)
    }

def generate_analysis_report(cycle_id, cycle_data, pnl_data, output_dir="internal/strategies/cyclehedge"):
    """ä¸ºå•ä¸ªå‘¨æœŸç”Ÿæˆåˆ†ææŠ¥å‘Š"""
    if not pnl_data:
        return None
    
    report_filename = f"å‘¨æœŸåˆ†ææŠ¥å‘Š_{cycle_id}.md"
    report_path = os.path.join(output_dir, report_filename)
    
    orders = cycle_data['orders']
    position_stats = cycle_data['position_stats']
    
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(f"# CycleHedgeç­–ç•¥å‘¨æœŸåˆ†ææŠ¥å‘Š - {cycle_id}\n\n")
        f.write(f"**å‘¨æœŸ**: {cycle_data['market_slug']}\n")
        if cycle_data.get('log_file'):
            f.write(f"**æ—¥å¿—æ–‡ä»¶**: {cycle_data['log_file']}\n")
        if cycle_data.get('log_create_time'):
            f.write(f"**æ—¥å¿—åˆ›å»ºæ—¶é—´**: {cycle_data['log_create_time']}\n")
        f.write(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write("---\n\n")
        
        f.write("## ğŸ“Š æ‰§è¡Œæ‘˜è¦\n\n")
        f.write("| æŒ‡æ ‡ | æ•°å€¼ | çŠ¶æ€ |\n")
        f.write("|------|------|------|\n")
        f.write(f"| **è®¢å•æ•°** | {pnl_data['orders_count']}ç¬” | {'âœ…' if pnl_data['orders_count'] > 0 else 'âš ï¸'} |\n")
        f.write(f"| **æœ€ç»ˆUPæŒä»“** | {pnl_data['final_up_shares']:.2f} shares | âœ… |\n")
        f.write(f"| **æœ€ç»ˆDOWNæŒä»“** | {pnl_data['final_down_shares']:.2f} shares | âœ… |\n")
        f.write(f"| **æŒä»“å¹³è¡¡åº¦** | {pnl_data['balance_ratio']:.2f}% | {'âœ…âœ…âœ…' if pnl_data['balance_ratio'] >= 95 else 'âœ…' if pnl_data['balance_ratio'] >= 90 else 'âš ï¸'} |\n")
        f.write(f"| **æ€»æˆæœ¬** | {pnl_data['total_cost']:.4f} USDC | âœ… |\n")
        f.write(f"| **æœ€åæƒ…å†µPnL** | {pnl_data['worst_case_pnl']:+.4f} USDC | {'âœ…âœ…âœ…' if pnl_data['worst_case_pnl'] > 0 else 'âš ï¸' if pnl_data['worst_case_pnl'] == 0 else 'âŒ'} |\n")
        if pnl_data['total_cost'] > 0:
            profit_ratio = pnl_data['worst_case_pnl']/pnl_data['total_cost']*100
            f.write(f"| **ç›ˆåˆ©æ¯”ä¾‹** | {profit_ratio:.2f}% | {'âœ…âœ…âœ…' if profit_ratio > 3 else 'âœ…' if profit_ratio > 0 else 'âš ï¸'} |\n")
        
        f.write("\n---\n\n")
        f.write("## ğŸ“‹ è®¢å•ç»Ÿè®¡\n\n")
        if pnl_data['orders_count'] > 0:
            f.write(f"- **æ€»è®¢å•æ•°**: {pnl_data['orders_count']}ç¬”\n")
            f.write(f"- **UPè®¢å•**: {pnl_data['up_orders_count']}ç¬” ({pnl_data['up_order_total']:.2f} shares, {pnl_data['up_order_amount']:.4f} USDC)\n")
            f.write(f"- **DOWNè®¢å•**: {pnl_data['down_orders_count']}ç¬” ({pnl_data['down_order_total']:.2f} shares, {pnl_data['down_order_amount']:.4f} USDC)\n")
            if pnl_data['first_order_time'] and pnl_data['last_order_time']:
                f.write(f"- **è®¢å•æ—¶é—´èŒƒå›´**: {pnl_data['first_order_time']} åˆ° {pnl_data['last_order_time']}\n")
        else:
            f.write("**æ³¨æ„**: æ—¥å¿—æ–‡ä»¶ä¸­æœªæ‰¾åˆ°è®¢å•è®°å½•ã€‚\n\n")
            f.write("**å¯èƒ½åŸå› **:\n")
            f.write("1. æ—¥å¿—æ–‡ä»¶åˆ›å»ºæ™šäº†ï¼Œæ—©æœŸè®¢å•æ²¡æœ‰è®°å½•\n")
            f.write("2. è®¢å•è®°å½•åœ¨å…¶ä»–æ—¥å¿—æ–‡ä»¶ä¸­\n")
            f.write("3. è®¢å•è®°å½•æ ¼å¼ä¸åŒ\n\n")
        
        f.write("\n---\n\n")
        f.write("## ğŸ“Š æŒä»“åˆ†æ\n\n")
        f.write(f"- **æœ€ç»ˆUPæŒä»“**: {pnl_data['final_up_shares']:.2f} shares\n")
        f.write(f"- **æœ€ç»ˆDOWNæŒä»“**: {pnl_data['final_down_shares']:.2f} shares\n")
        f.write(f"- **æ€»æŒä»“**: {pnl_data['final_up_shares'] + pnl_data['final_down_shares']:.2f} shares\n")
        f.write(f"- **æŒä»“å¹³è¡¡åº¦**: {pnl_data['balance_ratio']:.2f}%\n")
        f.write(f"- **æœªå¯¹å†²**: {max_shares - min_shares:.2f} shares\n")
        f.write(f"- **æŒä»“ç»Ÿè®¡è®°å½•æ•°**: {len(position_stats)}\n")
        f.write(f"- **é¦–æ¬¡æŒä»“ç»Ÿè®¡**: {pnl_data['first_stat_time']}\n")
        f.write(f"- **æœ€åæŒä»“ç»Ÿè®¡**: {pnl_data['last_stat_time']}\n")
        
        f.write("\n---\n\n")
        f.write("## ğŸ’° æˆæœ¬åˆ†æ\n\n")
        f.write(f"- **UPæˆæœ¬**: {pnl_data['final_up_cost']:.4f} USDC\n")
        f.write(f"- **DOWNæˆæœ¬**: {pnl_data['final_down_cost']:.4f} USDC\n")
        f.write(f"- **æ€»æˆæœ¬**: {pnl_data['total_cost']:.4f} USDC\n")
        if pnl_data['final_up_shares'] > 0:
            f.write(f"- **UPå¹³å‡ä»·æ ¼**: {pnl_data['up_avg_price']:.6f} USDC/share ({pnl_data['up_avg_price']*100:.2f}c)\n")
        if pnl_data['final_down_shares'] > 0:
            f.write(f"- **DOWNå¹³å‡ä»·æ ¼**: {pnl_data['down_avg_price']:.6f} USDC/share ({pnl_data['down_avg_price']*100:.2f}c)\n")
        if pnl_data['final_up_shares'] > 0 and pnl_data['final_down_shares'] > 0:
            total_avg = pnl_data['up_avg_price'] + pnl_data['down_avg_price']
            f.write(f"- **å¹³å‡æˆæœ¬åˆè®¡**: {total_avg:.6f} USDC/set ({total_avg*100:.2f}c)\n")
            f.write(f"- **é”å®šåˆ©æ¶¦**: {100 - (total_avg*100):.2f}c per set\n")
        
        f.write("\n---\n\n")
        f.write("## ğŸ’° PnLåˆ†æ\n\n")
        f.write(f"- **UPèƒœå‡ºPnL**: {pnl_data['pnl_up_win']:+.4f} USDC\n")
        f.write(f"- **DOWNèƒœå‡ºPnL**: {pnl_data['pnl_down_win']:+.4f} USDC\n")
        f.write(f"- **æœ€åæƒ…å†µPnL**: {pnl_data['worst_case_pnl']:+.4f} USDC\n")
        if pnl_data['total_cost'] > 0:
            f.write(f"- **ç›ˆåˆ©æ¯”ä¾‹**: {pnl_data['worst_case_pnl']/pnl_data['total_cost']*100:.2f}%\n")
    
    return report_path

def main():
    """ä¸»å‡½æ•°ï¼šåˆ†ææ‰€æœ‰æ—¥å¿—æ–‡ä»¶"""
    log_dir = "logs"
    output_dir = "lab"
    report_dir = "internal/strategies/cyclehedge"
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(output_dir, exist_ok=True)
    os.makedirs(report_dir, exist_ok=True)
    
    # æŸ¥æ‰¾æ‰€æœ‰æ—¥å¿—æ–‡ä»¶
    log_files = sorted(Path(log_dir).glob("btc-updown-15m-*.log"), key=lambda p: p.stat().st_mtime)
    
    if not log_files:
        print(f"âŒ æœªæ‰¾åˆ°æ—¥å¿—æ–‡ä»¶åœ¨ {log_dir} ç›®å½•")
        return
    
    print(f"æ‰¾åˆ° {len(log_files)} ä¸ªæ—¥å¿—æ–‡ä»¶")
    
    # åˆå¹¶æ‰€æœ‰å‘¨æœŸçš„æ•°æ®
    all_cycles = {}
    
    for log_file in log_files:
        print(f"\nåˆ†æ: {log_file.name}")
        cycles = defaultdict(lambda: {
            'orders': [],
            'position_stats': [],
            'cycle_id': None,
            'market_slug': None,
            'log_file': log_file.name,
            'log_create_time': datetime.fromtimestamp(log_file.stat().st_mtime).strftime('%Y-%m-%d %H:%M:%S')
        })
        
        order_ids_seen = set()
        
        try:
            with open(log_file, 'r', encoding='utf-8', errors='ignore') as f:
                for line_num, line in enumerate(f, 1):
                    parsed = parse_log_line(line)
                    if not parsed:
                        continue
                    
                    # æå–è®¢å•
                    order = extract_order_from_line(line, parsed)
                    if order:
                        order_key = f"{order['order_id']}"
                        if order_key not in order_ids_seen:
                            cycle_id = extract_cycle_id_from_market(order['market'])
                            if cycle_id:
                                cycles[cycle_id]['cycle_id'] = cycle_id
                                cycles[cycle_id]['market_slug'] = order['market']
                                cycles[cycle_id]['orders'].append(order)
                                order_ids_seen.add(order_key)
                    
                    # æå–æŒä»“ç»Ÿè®¡
                    position_stat = extract_position_stats(line, parsed)
                    if position_stat:
                        cycle_id = extract_cycle_id_from_market(position_stat['market'])
                        if cycle_id:
                            cycles[cycle_id]['cycle_id'] = cycle_id
                            cycles[cycle_id]['market_slug'] = position_stat['market']
                            cycles[cycle_id]['position_stats'].append(position_stat)
        except Exception as e:
            print(f"  âš ï¸  è¯»å–æ–‡ä»¶å‡ºé”™: {e}")
            continue
        
        for cycle_id, cycle_data in cycles.items():
            if cycle_id in all_cycles:
                # åˆå¹¶è®¢å•å’ŒæŒä»“ç»Ÿè®¡
                all_cycles[cycle_id]['orders'].extend(cycle_data['orders'])
                all_cycles[cycle_id]['position_stats'].extend(cycle_data['position_stats'])
            else:
                all_cycles[cycle_id] = cycle_data
    
    # å»é‡è®¢å•
    for cycle_id in all_cycles:
        orders = all_cycles[cycle_id]['orders']
        seen_ids = set()
        unique_orders = []
        for order in orders:
            if order['order_id'] not in seen_ids:
                unique_orders.append(order)
                seen_ids.add(order['order_id'])
        all_cycles[cycle_id]['orders'] = unique_orders
    
    print(f"\n{'='*80}")
    print(f"æ€»å…±æ‰¾åˆ° {len(all_cycles)} ä¸ªå‘¨æœŸ")
    print(f"{'='*80}")
    
    # ä¸ºæ¯ä¸ªå‘¨æœŸç”ŸæˆCSVå’Œåˆ†ææŠ¥å‘Š
    summary_data = []
    
    for cycle_id in sorted(all_cycles.keys()):
        cycle_data = all_cycles[cycle_id]
        
        # ç”ŸæˆCSVï¼ˆå¦‚æœæœ‰è®¢å•ï¼‰
        csv_path = generate_csv_for_cycle(cycle_id, cycle_data, output_dir)
        if csv_path:
            print(f"âœ… CSVå·²ç”Ÿæˆ: {csv_path}")
        
        # åˆ†æPnL
        pnl_data = analyze_cycle_pnl(cycle_id, cycle_data)
        if pnl_data:
            # ç”Ÿæˆåˆ†ææŠ¥å‘Š
            report_path = generate_analysis_report(cycle_id, cycle_data, pnl_data, report_dir)
            if report_path:
                print(f"âœ… åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
            
            summary_data.append(pnl_data)
    
    # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
    if summary_data:
        summary_path = os.path.join(report_dir, "æ‰€æœ‰å‘¨æœŸæ±‡æ€»æŠ¥å‘Š.md")
        with open(summary_path, 'w', encoding='utf-8') as f:
            f.write("# CycleHedgeç­–ç•¥æ‰€æœ‰å‘¨æœŸæ±‡æ€»æŠ¥å‘Š\n\n")
            f.write(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            f.write("---\n\n")
            
            f.write("## ğŸ“Š æ±‡æ€»ç»Ÿè®¡\n\n")
            f.write("| å‘¨æœŸID | è®¢å•æ•° | UPæŒä»“ | DOWNæŒä»“ | æ€»æˆæœ¬ | æœ€åPnL | ç›ˆåˆ©æ¯”ä¾‹ | å¹³è¡¡åº¦ |\n")
            f.write("|--------|--------|--------|----------|--------|---------|----------|--------|\n")
            
            total_orders = 0
            total_cost = 0
            total_pnl = 0
            total_cycles = len(summary_data)
            profitable_cycles = 0
            
            for pnl in summary_data:
                total_orders += pnl['orders_count']
                total_cost += pnl['total_cost']
                total_pnl += pnl['worst_case_pnl']
                if pnl['worst_case_pnl'] > 0:
                    profitable_cycles += 1
                
                profit_ratio = (pnl['worst_case_pnl']/pnl['total_cost']*100) if pnl['total_cost'] > 0 else 0
                
                f.write(f"| {pnl['cycle_id']} | {pnl['orders_count']} | {pnl['final_up_shares']:.2f} | {pnl['final_down_shares']:.2f} | {pnl['total_cost']:.4f} | {pnl['worst_case_pnl']:+.4f} | {profit_ratio:.2f}% | {pnl['balance_ratio']:.2f}% |\n")
            
            f.write(f"\n**æ€»è®¡**: {total_cycles}ä¸ªå‘¨æœŸ, {total_orders}ç¬”è®¢å•, {total_cost:.4f} USDCæ€»æˆæœ¬, {total_pnl:+.4f} USDCæ€»ç›ˆåˆ©\n")
            f.write(f"**å¹³å‡ç›ˆåˆ©æ¯”ä¾‹**: {(total_pnl/total_cost*100) if total_cost > 0 else 0:.2f}%\n")
            f.write(f"**ç›ˆåˆ©å‘¨æœŸæ•°**: {profitable_cycles}/{total_cycles} ({profitable_cycles/total_cycles*100:.1f}%)\n")
        
        print(f"\nâœ… æ±‡æ€»æŠ¥å‘Šå·²ç”Ÿæˆ: {summary_path}")
    
    print(f"\n{'='*80}")
    print("âœ… æ‰€æœ‰å‘¨æœŸåˆ†æå®Œæˆï¼")
    print(f"{'='*80}")

if __name__ == "__main__":
    main()
